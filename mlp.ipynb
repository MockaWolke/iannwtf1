{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68a881f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def random_data(datatype =\"xor\"):\n",
    "    data=[[0,0],[1,0],[0,1],[1,1]]\n",
    "    if datatype==\"xor\":\n",
    "        return (np.array(data),np.array([int(a[0] ^ a[1]) for a in data]) )\n",
    "    elif datatype==\"and\":\n",
    "        return (np.array(data),np.array([int(a[0] and a[1]) for a in data]) )\n",
    "    elif datatype==\"or\":\n",
    "        return (np.array(data),np.array([int(a[0] or a[1]) for a in data]) )\n",
    "    elif datatype==\"nand\":\n",
    "        return (np.array(data),1-np.array([int(a[0] and a[1]) for a in data]))\n",
    "    elif datatype==\"nor\":\n",
    "        return (np.array(data),1-np.array([int(a[0] or a[1]) for a in data]))\n",
    "    \n",
    "    \n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "    \n",
    "def sigmoidprime(x):\n",
    "    return np.exp(x)/((np.exp(x)+1)**2)\n",
    "\n",
    "def squared_error(x,y):\n",
    "    return (x-y)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b53f574",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Our_Mlp():\n",
    "    def __init__(self,number_of_h_ls=1):\n",
    "        \n",
    "        self.n_h_ls=number_of_h_ls\n",
    "        self.h_ls_values = np.zeros((4,number_of_h_ls))\n",
    "        self.h_ls_weights = np.random.normal(-5,5,(4,number_of_h_ls,4))\n",
    "        self.h_ls_weights[:,0,2:4]=np.nan # first layer has only two inputs -> set other weights to nan\n",
    "        self.h_ls_alpha =  np.ones((4,number_of_h_ls)) # we set the learning_rate to one\n",
    "        self.h_ls_biases =  np.random.normal(-5,5,(4,number_of_h_ls))\n",
    "        \n",
    "        \n",
    "        # We will store the drives of the perceptrons for the backprob\n",
    "        \n",
    "        self.h_ls_drives = np.zeros((4,number_of_h_ls))\n",
    "        \n",
    "        self.h_ls_deltas  = np.zeros((4,number_of_h_ls))\n",
    "        \n",
    "        \n",
    "        # No we define the value, weights, bias, learning rate of our output neuron\n",
    "        \n",
    "        self.o_v=0\n",
    "        self.o_w=np.random.normal(-5,5,4)\n",
    "        self.o_b=float(np.random.normal(-5,5,1))\n",
    "        self.o_alpha=1\n",
    "        self.o_delta = 0\n",
    "        self.o_drive = 0\n",
    "        \n",
    "        \n",
    "    def forward_step(self,input_data):\n",
    "        \"\"\"\n",
    "        input_data is supposed to an 1d numpy.array with shape=(2)\n",
    "        \"\"\"\n",
    "        \n",
    "        # So now we have to calculate the input for the perceptrons of the first hidden layer which get 2 inputs each\n",
    "        for y in range(0,4):\n",
    "            \n",
    "            self.h_ls_drives[y,0]=np.dot(self.h_ls_weights[y,0,0:2],input_data) + self.h_ls_biases[y,0]\n",
    "\n",
    "            self.h_ls_values[y,0]=sigmoid(self.h_ls_drives[y,0])\n",
    "            \n",
    "        # Calculate the next hidden layers\n",
    "            \n",
    "        for x in range(1,self.n_h_ls):\n",
    "            for y in range(0,4):\n",
    "                self.h_ls_drives[y,x]=np.dot(self.h_ls_weights[y,x,:],self.h_ls_values[:,x-1]) + self.h_ls_biases[y,x]\n",
    "                self.h_ls_values[y,x]=sigmoid(self.h_ls_drives[y,x])\n",
    "        \n",
    "        # Last layer to output neuron\n",
    "        self.o_drive= np.dot(self.o_w,self.h_ls_values[:,-1]) + self.o_b\n",
    "        \n",
    "        self.o_v= sigmoid(self.o_drive)\n",
    "        \n",
    "        # let's return the output\n",
    "        \n",
    "        return self.o_v\n",
    "    \n",
    "    \n",
    "    \n",
    "    def backprop_step(self,solution):\n",
    "        \n",
    "        self.o_delta = 2*(self.o_v-solution)* sigmoidprime(self.o_drive)\n",
    "        \n",
    "        # update the weitghs\n",
    "        \n",
    "        self.o_w -= self.o_alpha* self.o_w * self.o_delta\n",
    "        \n",
    "        # update the bias\n",
    "        \n",
    "        self.o_b -=  self.o_alpha * self.o_delta\n",
    "        \n",
    "        # now for the neurons of the last hidden layer\n",
    "        for y in range(0,4):\n",
    "            self.h_ls_deltas[y,-1] = sigmoidprime(self.h_ls_drives[y,-1]) * self.o_w[y] * self.o_delta\n",
    "            self.h_ls_weights[y,-1,:] -=  self.h_ls_weights[y,-1,:]  * self.h_ls_alpha[y,-1] * self.h_ls_deltas[y,-1]\n",
    "            self.h_ls_biases[y,-1] -=  self.h_ls_alpha[y,-1] * self.h_ls_deltas[y,-1]\n",
    "            \n",
    "        # for the rest of the hidden layer\n",
    "        \n",
    "        for x in range(self.n_h_ls-2,-1,-1):\n",
    "            for y in range(0,4):\n",
    "                \n",
    "                self.h_ls_deltas[y,x] = np.dot(self.h_ls_deltas[:,x+1],self.h_ls_weights[:,x+1,y]) * sigmoidprime(self.h_ls_drives[y,x])\n",
    "                self.h_ls_weights[y,x,:] -= self.h_ls_weights[y,x,:] * self.h_ls_alpha[y,x] * self.h_ls_deltas[y,x]\n",
    "                self.h_ls_biases[y,x]-= self.h_ls_alpha[y,x] * self.h_ls_deltas[y,x]\n",
    "                \n",
    "    def __str__(self):\n",
    "        text = f\"\"\"This is a neuronal network with {self.n_h_ls} hidden layers.\n",
    "The values are:\n",
    "{self.h_ls_values}\n",
    "\n",
    "{ self.o_v }\n",
    "\n",
    "The weights are:\n",
    "{self.h_ls_weights}\n",
    "\n",
    "{ self.o_w }\n",
    "\n",
    "The biases are:\n",
    "\n",
    "{self.h_ls_biases}\n",
    "\n",
    "{self.o_b}\n",
    "\n",
    "The deltas are:\n",
    "{self.h_ls_deltas}\n",
    "\n",
    "{ self.o_delta }\"\"\"\n",
    "        return text\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1151c4d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a neuronal network with 2 hidden layers.\n",
      "The values are:\n",
      "[[0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]]\n",
      "\n",
      "0\n",
      "\n",
      "The weights are:\n",
      "[[[-12.91094728  -1.03314306          nan          nan]\n",
      "  [ -7.78870969  -3.21795969   4.64209786  -7.07869367]]\n",
      "\n",
      " [[ -5.13025436   1.51766736          nan          nan]\n",
      "  [ -2.79773041  -7.45897045  -6.49155131  -5.87398766]]\n",
      "\n",
      " [[ -0.03649703  -9.65253198          nan          nan]\n",
      "  [-10.5947063   -3.80152139  -8.41497679  -0.81142178]]\n",
      "\n",
      " [[ -5.79357087  -6.8258              nan          nan]\n",
      "  [ -9.07628447  -9.93371717 -14.11426196  -4.19971483]]]\n",
      "\n",
      "[-12.12824406  -6.98467981   3.51023897  -2.06589874]\n",
      "\n",
      "The biases are:\n",
      "\n",
      "[[-1.96474972 -2.07411436]\n",
      " [-2.45654705  2.36004628]\n",
      " [-3.52201358 -6.2518209 ]\n",
      " [-7.60353177 -4.26862873]]\n",
      "\n",
      "-16.8631907933523\n",
      "\n",
      "The deltas are:\n",
      "[[0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]]\n",
      "\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "a = Our_Mlp(2)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b545b540-70c8-4520-93e9-4729e90e3331",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0, 0],\n",
       "        [1, 0],\n",
       "        [0, 1],\n",
       "        [1, 1]]),\n",
       " array([0, 1, 1, 0]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = random_data()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab603996-5938-473e-b256-86ec87644d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tick(MLP,data):\n",
    "    input_values, solution = data\n",
    "    \n",
    "    assert(input_values.shape[0]==solution.size)\n",
    "    \n",
    "    accuracy_of_loss = 0\n",
    "    \n",
    "    for i, input_value in enumerate(input_values):\n",
    "        accuracy_of_loss+= squared_error(MLP.forward_step(input_value),solution[i]) < 0.5\n",
    "        MLP.backprop_step(solution[i])\n",
    "        \n",
    "    return accuracy_of_loss/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11fd83d5-48fa-4847-a407-949af8736bc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a neuronal network with 2 hidden layers.\n",
      "The values are:\n",
      "[[1.23275987e-07 1.10904679e-01]\n",
      " [2.30783698e-03 9.12361825e-01]\n",
      " [1.83027482e-06 1.90643713e-03]\n",
      " [1.64932018e-09 1.34985692e-02]]\n",
      "\n",
      "2.067657581491791e-11\n",
      "\n",
      "The weights are:\n",
      "[[[-12.91094729  -1.03314306          nan          nan]\n",
      "  [ -7.78870968  -3.21795969   4.64209786  -7.07869367]]\n",
      "\n",
      " [[ -5.13025438   1.51766736          nan          nan]\n",
      "  [ -2.7977304   -7.45897043  -6.49155129  -5.87398764]]\n",
      "\n",
      " [[ -0.03649703  -9.65253198          nan          nan]\n",
      "  [-10.5947063   -3.80152139  -8.41497679  -0.81142178]]\n",
      "\n",
      " [[ -5.79357087  -6.8258              nan          nan]\n",
      "  [ -9.07628447  -9.93371717 -14.11426196  -4.19971483]]]\n",
      "\n",
      "[-12.12824408  -6.98467982   3.51023898  -2.06589875]\n",
      "\n",
      "The biases are:\n",
      "\n",
      "[[-1.96474972 -2.07411437]\n",
      " [-2.45654704  2.36004628]\n",
      " [-3.52201358 -6.2518209 ]\n",
      " [-7.60353177 -4.26862873]]\n",
      "\n",
      "-16.863190791787467\n",
      "\n",
      "The deltas are:\n",
      "[[ 1.16536379e-27 -1.02254718e-21]\n",
      " [ 1.62656244e-23 -4.77522860e-22]\n",
      " [-2.49458147e-27  5.71107231e-24]\n",
      " [ 1.67198430e-29 -2.35224048e-23]]\n",
      "\n",
      "8.550415748424173e-22\n"
     ]
    }
   ],
   "source": [
    "tick(a,data)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "774fef16-5f71-4f95-b534-37caa5b4a4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "erg=[]\n",
    "weights_of_first_neuron = [[],[],[],[]]\n",
    "\n",
    "x_axes= np.linspace(0,10000,num=100001)\n",
    "for i in range(0,len(x_axes)):\n",
    "    erg.append(tick(a,data))\n",
    "    if i % 100 == 0:\n",
    "        for z in range(0,4):\n",
    "            weights_of_first_neuron[z].append(a.h_ls_weights[0,1,z])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df49a8a3-76e9-4b9f-8898-b38489068340",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f28303e5340>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1332x756 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1,2)\n",
    "fig.set_size_inches(18.5, 10.5)\n",
    "ax[0].plot(x_axes,erg)\n",
    "\n",
    "ax[1].plot(range(0,len(weights_of_first_neuron[0])) , weights_of_first_neuron[0])\n",
    "ax[1].plot(range(0,len(weights_of_first_neuron[0])) , weights_of_first_neuron[1])\n",
    "ax[1].plot(range(0,len(weights_of_first_neuron[0])) , weights_of_first_neuron[2])\n",
    "ax[1].plot(range(0,len(weights_of_first_neuron[0])) , weights_of_first_neuron[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b537ea6-83bb-4af3-9082-40e0cb56bc5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a neuronal network with 2 hidden layers.\n",
      "The values are:\n",
      "[[1.23188237e-07 1.10899073e-01]\n",
      " [2.30518969e-03 9.12342331e-01]\n",
      " [1.83027773e-06 1.90645673e-03]\n",
      " [1.64932016e-09 1.34989161e-02]]\n",
      "\n",
      "2.0658963494609563e-11\n",
      "\n",
      "The weights are:\n",
      "[[[-12.91165754  -1.0331999           nan          nan]\n",
      "  [ -7.7881967   -3.21774775   4.64179212  -7.07822745]]\n",
      "\n",
      " [[ -5.13251319   1.51833558          nan          nan]\n",
      "  [ -2.79698033  -7.45697068  -6.48981091  -5.87241282]]\n",
      "\n",
      " [[ -0.03649703  -9.65253022          nan          nan]\n",
      "  [-10.59470879  -3.80152228  -8.41497877  -0.81142197]]\n",
      "\n",
      " [[ -5.79357088  -6.82580001          nan          nan]\n",
      "  [ -9.07628221  -9.93371469 -14.11425844  -4.19971378]]]\n",
      "\n",
      "[-12.13014406  -6.98577402   3.51078888  -2.06622238]\n",
      "\n",
      "The biases are:\n",
      "\n",
      "[[-1.96469471 -2.07418023]\n",
      " [-2.45610685  2.35977814]\n",
      " [-3.52201376 -6.25182066]\n",
      " [-7.60353177 -4.26862897]]\n",
      "\n",
      "-16.863034146810627\n",
      "\n",
      "The deltas are:\n",
      "[[ 1.16261502e-27 -1.02092065e-21]\n",
      " [ 1.62205159e-23 -4.76880242e-22]\n",
      " [-2.49013826e-27  5.70229872e-24]\n",
      " [ 1.66923675e-29 -2.34866232e-23]]\n",
      "\n",
      "8.535855453255868e-22\n"
     ]
    }
   ],
   "source": [
    "print(a)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
